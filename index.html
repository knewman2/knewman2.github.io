<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Kaleb S. Newman</title>

    <meta name="author" content="Kaleb S. Newman">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Kaleb S. Newman
                </p>
                <p>
		I'm a first-year Ph.D. student in Computer Science at <a href="https://www.princeton.edu/">Princeton University</a>, where I work in the <a href="https://visualai.princeton.edu/">Visual AI Lab</a> advised by <a href="https://www.cs.princeton.edu/~olgarus/">Dr. Olga Russakovsky</a>.
		My research interests lie broadly in computer vision, with a particular focus on how machines and humans internally reason about and represent the visual world.
		</p>
		<p>
		I received my Sc.B. in Computer Science from <a href="https://www.brown.edu/">Brown University</a> in 2025, focused in Artificial Intelligence and Visual Computing. 
		At Brown, I was fortunate to be advised by <a href="https://chensun.me/">Dr. Chen Sun</a> and <a href="https://serre-lab.clps.brown.edu/person/thomas-serre/">Dr. Tomas Serre</a>, and I also spent a summer at the University of Rochester working with <a href="https://zhenbai.io/">Dr. Zhen Bai</a>.
		</p>
		<p>
		Please feel free to reach out to chat about research or advice!
                </p>
                <p style="text-align:center">
                  <a href="mailto:kn3194@princeton.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=Uhlp6yYAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <span style="color: #888;">CV</span> &nbsp;/&nbsp;
                  <span style="color: #888;">Twitter</span> &nbsp;/&nbsp;
                  <span style="color: #888;">Github</span>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/KalebNewman.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/KalebNewman.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research interests lie broadly in computer vision, with a particular focus on how machines and humans internally reason about and represent the visual world. Conceptually, I'm guided by the <a href="https://www.pnas.org/doi/10.1073/pnas.1012933107">mental models view from cognitive science</a> and by <a href="https://en.wikipedia.org/wiki/Cognitive_map">cognitive maps in neuroscience</a>â€”both motivating internal world representations that can be queried and updated over time. My interests are ever-developing, but currently I'm interested in video understanding, world models, and multimodal understanding. Some papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          
          <!-- News Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>News</h2>
                <ul>
                  <li><strong>09/2025:</strong> Started my PhD at Princeton University ðŸ˜†ðŸš€</li>
                  <li><strong>01/2025:</strong> Honorable mention for the 2025 CRA Outstanding Undergraduate Researcher Award.</li>
                  <li><strong>09/2024:</strong> Presented "Do Pre-Trained Vision-Language Models Encode Object States" at ECCV 2024 in the EVAL-FoMo Workshop.</li>
                  <li><strong>10/2023:</strong> Presented and demoed "Supporting ASL Communication Between Hearing Parents and Deaf Children" at Assets 2023.</li>
                  <li><strong>10/2023:</strong> Presented "Building User-Centered ASL Communication Technologies for Parent-Child Interactions" at MIT URTC; awarded Top 5 paper distinction.</li>
                </ul>
              </td>
            </tr>
          </tbody></table>

          <!-- Publications Section -->
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <!-- Publication 1: ECCV 2024 Workshop Paper -->
    <tr bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div style="width:160px;height:160px;background-color:#f0f0f0;border-radius:10px;display:flex;align-items:center;justify-content:center;color:#666;font-size:12px;">Publication Image</div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2409.10488">
          <span class="papertitle">Do Pre-Trained Vision-Language Models Encode Object States?</span>
        </a>
        <br>
        <strong>K. Newman*</strong>,
        Shijie Wang,
        Yuan Zang,
        David Heffren,
        <a href="https://chensun.me/">Chen Sun</a>
        <br>
        <em>ECCV 2024 Workshop on Emergent Visual Abilities and Limits of Foundation Models</em>
        <br>
        <a href="https://arxiv.org/abs/2409.10488">arXiv</a>
        <p></p>
        <p>
        We investigate whether pre-trained vision-language models encode information about object states, finding that they can distinguish certain state changes but struggle with others.
        </p>
      </td>
    </tr>

    <!-- Publication 2: IDC 2025 -->
    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div style="width:160px;height:160px;background-color:#f0f0f0;border-radius:10px;display:flex;align-items:center;justify-content:center;color:#666;font-size:12px;">Publication Image</div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://dl.acm.org/doi/full/10.1145/3713043.3727054">
          <span class="papertitle">Leveraging Usefulness and Autonomy: Designing AI-Mediated ASL Communication Between Hearing Parents and Deaf Children</span>
        </a>
        <br>
        Yifan Li,
        Hecong Wang,
        Ekram Hossain,
        Madeleine Mann,
        Jingyan Yu,
        <strong>Kaleb Slater Newman</strong>,
        Ashley Bao,
        Athena Willis,
        Chigusa Kurumada,
        Wyatte C Hall,
        <a href="https://zhenbai.io/">Zhen Bai</a>
        <br>
        <em>Proceedings of the 24th Interaction Design and Children</em>, 512-526
        <br>
        <a href="https://dl.acm.org/doi/full/10.1145/3713043.3727054">paper</a>
        <p></p>
        <p>
        We explore the design of AI-mediated ASL communication technologies to support parent-child interactions between hearing parents and deaf children.
        </p>
      </td>
    </tr>

    <!-- Publication 3: ASSETS 2023 -->
    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div style="width:160px;height:160px;background-color:#f0f0f0;border-radius:10px;display:flex;align-items:center;justify-content:center;color:#666;font-size:12px;">Publication Image</div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://dl.acm.org/doi/abs/10.1145/3597638.3614511">
          <span class="papertitle">Supporting ASL Communication Between Hearing Parents and Deaf Children</span>
        </a>
        <br>
        E. Houssain,
        <strong>K. Newman</strong>,
        A. Bao,
        M. Mann,
        Y. Li,
        H. Wang,
        W. Hall,
        C. Kurumada,
        <a href="https://zhenbai.io/">Z. Bai</a>
        <br>
        <em>ACM SIGACCESS Conference on Computers and Accessibility</em>
        <br>
        <a href="https://dl.acm.org/doi/abs/10.1145/3597638.3614511">paper</a>
        <p></p>
        <p>
        We present a system to support ASL communication between hearing parents and deaf children, addressing accessibility challenges in family communication.
        </p>
      </td>
    </tr>

    <!-- Publication 4: MIT URTC 2023 -->
    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div style="width:160px;height:160px;background-color:#f0f0f0;border-radius:10px;display:flex;align-items:center;justify-content:center;color:#666;font-size:12px;">Publication Image</div>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10534918">
          <span class="papertitle">Building User-Centered ASL Communication Technologies for Parent-Child Interactions</span>
        </a>
        <br>
        <strong>A. Bao*</strong>,
        <strong>K. Newman*</strong>,
        M. Mann,
        E. Houssain,
        C. Kurumada,
        <a href="https://zhenbai.io/">Z. Bai</a>
        <br>
        <em>MIT Undergraduate Research & Technology Conference 2023</em> <strong>(Top 5 paper distinction)</strong>
        <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/10534918">paper</a>
        <p></p>
        <p>
        We present a user-centered approach to developing ASL communication technologies, focusing on the needs of hearing parents and deaf children.
        </p>
      </td>
    </tr>

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website template from <a href="https://github.com/jonbarron/jonbarron.github.io">Jon Barron</a>. Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
